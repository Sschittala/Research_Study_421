{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "TORCH = torch.__version__.split('+')[0]\n",
        "CUDA = 'cu' + torch.version.cuda.replace('.', '')\n",
        "\n",
        "# 2. Install torch-scatter, torch-sparse, and finally, torch-geometric\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVEArGxNd_sU",
        "outputId": "460eb47d-25a6-48f7-86cd-08453f34734c"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.9.0+cu126.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsRa1G6rdSIM",
        "outputId": "bfaeebbd-4ff4-4435-9629-c8dc9b8400f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes: 2708\n",
            "Features: 1433\n",
            "Classes: 7\n",
            "\n",
            "Total number of directed edges: 10556\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "dataset = Planetoid(root='./data/Cora', name='Cora')\n",
        "data = dataset[0]\n",
        "G = to_networkx(data, to_undirected=True)\n",
        "\n",
        "print(f\"Nodes: {data.num_nodes}\")\n",
        "print(f\"Features: {data.num_node_features}\")\n",
        "print(f\"Classes: {dataset.num_classes}\")\n",
        "\n",
        "edge_index = data.edge_index\n",
        "\n",
        "\n",
        "num_edges_to_print = min(5, edge_index.shape[1])\n",
        "\n",
        "# Print the total number of edges\n",
        "print(f\"\\nTotal number of directed edges: {data.num_edges}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "degree_centrality = nx.degree_centrality(G)\n",
        "\n",
        "closeness_centrality = nx.closeness_centrality(G)\n",
        "\n",
        "betweenness_centrality = nx.betweenness_centrality(G)\n",
        "\n",
        "node_properties_df = pd.DataFrame({\n",
        "    'node_id': list(G.nodes()),\n",
        "    'degree_centrality': [degree_centrality[n] for n in G.nodes()],\n",
        "    'closeness_centrality': [closeness_centrality[n] for n in G.nodes()],\n",
        "    'betweenness_centrality': [betweenness_centrality[n] for n in G.nodes()]\n",
        "}).set_index('node_id')\n",
        "\n",
        "print(\"Sample Node Properties:\")\n",
        "print(node_properties_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7EmqHrapGyy",
        "outputId": "174a593f-040f-4ce2-a575-86c9e6a26ae2"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Node Properties:\n",
            "         degree_centrality  closeness_centrality  betweenness_centrality\n",
            "node_id                                                                 \n",
            "0                 0.001108              0.144255            9.766154e-07\n",
            "1                 0.001108              0.151453            1.080477e-03\n",
            "2                 0.001847              0.179168            4.050816e-03\n",
            "3                 0.000369              0.000369            0.000000e+00\n",
            "4                 0.001847              0.153266            5.511762e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Calculate and Add Rank to DataFrame ---\n",
        "\n",
        "# The TANS method provides the rank (percentile) of each property\n",
        "# among all nodes to the LLM (Table 2 in the paper).\n",
        "for col in node_properties_df.columns:\n",
        "    # Use .rank(pct=True) to calculate percentile rank (0 to 1)\n",
        "    # Multiply by 100 to get the percentage rank (0 to 100)\n",
        "    node_properties_df[f'{col}_rank'] = node_properties_df[col].rank(pct=True) * 100\n",
        "\n",
        "print(\"\\nSample Node Properties with Ranks:\")\n",
        "print(node_properties_df[['degree_centrality', 'degree_centrality_rank']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiDHQYGxzKwI",
        "outputId": "eb44d556-698b-4936-dfa5-856c9c3cc3f3"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Node Properties with Ranks:\n",
            "         degree_centrality  degree_centrality_rank\n",
            "node_id                                           \n",
            "0                 0.001108               49.667651\n",
            "1                 0.001108               49.667651\n",
            "2                 0.001847               79.431315\n",
            "3                 0.000369                8.973412\n",
            "4                 0.001847               79.431315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "# Load node data\n",
        "cora_content = pd.read_csv(\"/content/cora/cora.content\", sep=\"\\t\", header=None)\n",
        "\n",
        "# Last column is the class label\n",
        "cora_content.columns = [\"id\"] + [f\"w{i}\" for i in range(1, cora_content.shape[1]-1)] + [\"class\"]\n",
        "\n",
        "# Load edge list (citations)\n",
        "edges = pd.read_csv(\"/content/cora/cora.cites\", sep=\"\\t\", header=None, names=[\"source\", \"target\"])\n",
        "\n",
        "# Build directed citation graph\n",
        "G = nx.from_pandas_edgelist(edges, source=\"source\", target=\"target\", create_using=nx.DiGraph())\n",
        "\n",
        "def bow_to_text(row):\n",
        "    words = [col for col in row.index if col.startswith(\"w\") and row[col] == 1]\n",
        "    return \" \".join(words)\n",
        "\n",
        "node_text = {\n",
        "    row[\"id\"]: bow_to_text(row)  # 'id' must match G node IDs\n",
        "    for _, row in cora_content.iterrows()\n",
        "}\n",
        "\n",
        "def get_original_text(node_id):\n",
        "    \"\"\"\n",
        "    Placeholder: In a full TANS implementation, this reads the actual title\n",
        "    and abstract text from the raw Cora dataset files.\n",
        "    \"\"\"\n",
        "    # Using a generic placeholder for demonstration\n",
        "    if node_id not in node_text:\n",
        "      return \"No text found for this node.\"\n",
        "    return node_text[node_id]"
      ],
      "metadata": {
        "id": "1Jvf6HURzNaa"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_nodes = list(set(G.nodes()).intersection(node_text.keys()))\n",
        "sample_node_id = common_nodes[0]"
      ],
      "metadata": {
        "id": "DDbo_tsuZKiK"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_neighbor_texts(graph, node_id, num_neighbors=5):\n",
        "    \"\"\"\n",
        "    Retrieves up to num_neighbors real texts of connected nodes.\n",
        "    \"\"\"\n",
        "    if node_id not in graph:\n",
        "        return \"Node not found in graph.\"\n",
        "\n",
        "    neighbors = list(graph.neighbors(node_id))\n",
        "\n",
        "    if len(neighbors) == 0:\n",
        "        return \"No connected nodes found.\"\n",
        "\n",
        "    selected = np.random.choice(\n",
        "        neighbors,\n",
        "        min(num_neighbors, len(neighbors)),\n",
        "        replace=False\n",
        "    )\n",
        "\n",
        "    return \"\\n\".join(\n",
        "        [\n",
        "            f\"{n}: {get_original_text(n)[:200]}...\"\n",
        "            for n in selected\n",
        "        ]\n",
        "    )\n",
        "test_node = cora_content.iloc[0][\"id\"]\n",
        "\n",
        "print(\"--- Original Text ---\")\n",
        "print(get_original_text(test_node))\n",
        "\n",
        "print(\"\\n--- Neighbor Texts ---\")\n",
        "print(get_neighbor_texts(G, test_node, num_neighbors=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl_60SlSVvsf",
        "outputId": "1cf93258-65af-47ef-e128-eb86d498c196"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Original Text ---\n",
            "w119 w126 w177 w253 w352 w457 w508 w522 w620 w649 w699 w703 w735 w846 w903 w1206 w1210 w1237 w1353 w1427\n",
            "\n",
            "--- Neighbor Texts ---\n",
            "686532: w133 w174 w212 w329 w330 w336 w435 w522 w565 w704 w726 w730 w798 w1171 w1209 w1212 w1258 w1302 w1329 w1340 w1424 w1426...\n",
            "31349: w457 w649 w903 w1210 w1274...\n",
            "1129442: w133 w136 w232 w238 w251 w265 w331 w469 w699 w875 w903 w1020 w1098 w1136 w1274 w1349 w1353 w1360...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Final TANS Prompt Generation Function (Steps 2 & 3) ---\n",
        "\n",
        "def generate_tans_prompt(graph, node_id, properties_df, classes):\n",
        "    \"\"\"\n",
        "    Generates the complete, structured TANS prompt using all information.\n",
        "    \"\"\"\n",
        "    # Retrieve properties and ranks\n",
        "    degree = properties_df.loc[node_id, 'degree_centrality']\n",
        "    rank_degree = properties_df.loc[node_id, 'degree_centrality_rank']\n",
        "\n",
        "    # 1. Get original text (Prompt 2)\n",
        "    original_text = get_original_text(node_id)\n",
        "\n",
        "    # 2. Get neighbor texts (Prompt 3)\n",
        "    neighbor_texts = get_neighbor_texts(graph, node_id, num_neighbors=5)\n",
        "\n",
        "    # 3. Construct the full prompt (Prefix, Text, Neighbor, Property, Suffix)\n",
        "    prompt = f\"\"\"\n",
        "Given a node from a citation network graph, where the node type is paper.\n",
        "The original node description is: \"{original_text}\".\n",
        "\n",
        "The following are the textual information of 5 connected nodes. The descriptions are:\n",
        "{neighbor_texts}\n",
        "\n",
        "Node Properties:\n",
        "- Degree Centrality value: {degree:.4f}, ranked as {rank_degree:.2f}% among all nodes.\n",
        "- Closeness Centrality value: {properties_df.loc[node_id, 'closeness_centrality']:.4f}.\n",
        "- Betweenness Centrality value: {properties_df.loc[node_id, 'betweenness_centrality']:.4f}.\n",
        "\n",
        "Output the potential class of the node among the following classes: {classes}.\n",
        "Provide reasons for your assessment. Your answer should be less than 200 words.\n",
        "\"\"\"\n",
        "    return prompt.strip()"
      ],
      "metadata": {
        "id": "-yS0SiSrzU9Z"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure node_properties_df is indexed by node_id\n",
        "\n",
        "# Find nodes common to G, node_text, and node_properties_df\n",
        "common_nodes = list(\n",
        "    set(G.nodes()).intersection(node_text.keys()).intersection(node_properties_df.index)\n",
        ")\n",
        "\n",
        "# Pick a sample node\n",
        "sample_node_id = common_nodes[0]  # safe\n"
      ],
      "metadata": {
        "id": "XeaVuw3La1iC"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sample node ID:\", sample_node_id)\n",
        "print(\"In G:\", sample_node_id in G)\n",
        "print(\"In node_text:\", sample_node_id in node_text)\n",
        "print(\"In node_properties_df:\", sample_node_id in node_properties_df.index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7f0Rcr_arkM",
        "outputId": "866f4c58-3e8e-463e-a416-e43aa28a7807"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample node ID: 128\n",
            "In G: True\n",
            "In node_text: True\n",
            "In node_properties_df: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classes_cora = [\"Neural Networks\", \"Probabilistic Methods\", \"Genetic Algorithms\", \"Theory\", \"Case Based\", \"Reinforcement Learning\", \"Rule Learning\"]\n",
        "\n",
        "\n",
        "common_nodes = list(\n",
        "    set(G.nodes()).intersection(node_text.keys()).intersection(node_properties_df.index)\n",
        ")\n",
        "\n",
        "# Pick a sample node\n",
        "sample_node_id = common_nodes[0]\n",
        "\n",
        "# Generate TANS prompt\n",
        "final_prompt = generate_tans_prompt(\n",
        "    G,\n",
        "    sample_node_id,\n",
        "    node_properties_df,\n",
        "    classes_cora\n",
        ")\n",
        "print(\"\\n--- Final Generated TANS Prompt Example ---\")\n",
        "print(final_prompt)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jCHPh1vzWTr",
        "outputId": "4a7cec05-0500-49f3-db94-0b4386e06f7c"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Generated TANS Prompt Example ---\n",
            "Given a node from a citation network graph, where the node type is paper.\n",
            "The original node description is: \"w2 w42 w188 w213 w358 w405 w465 w506 w508 w582 w636 w875 w989 w1072 w1231 w1232 w1259 w1264 w1275 w1394\".\n",
            "\n",
            "The following are the textual information of 5 connected nodes. The descriptions are:\n",
            "20526: w100 w241 w331 w335 w549 w582 w633 w649 w830 w875 w1072 w1119 w1132 w1156 w1178 w1193 w1207 w1264 w1275 w1360 w1433...\n",
            "91975: w158 w212 w238 w357 w447 w521 w595 w605 w624 w649 w656 w724 w830 w875 w940 w1072 w1264 w1275 w1309 w1360 w1424...\n",
            "1114125: w94 w100 w335 w402 w582 w605 w774 w981 w1156 w1178 w1264 w1293 w1307 w1315 w1321 w1382...\n",
            "39403: w127 w293 w335 w549 w582 w605 w626 w774 w912 w973 w989 w1133 w1156 w1263 w1264 w1293 w1307 w1315 w1321 w1382...\n",
            "\n",
            "Node Properties:\n",
            "- Degree Centrality value: 0.0015, ranked as 67.06% among all nodes.\n",
            "- Closeness Centrality value: 0.1304.\n",
            "- Betweenness Centrality value: 0.0007.\n",
            "\n",
            "Output the potential class of the node among the following classes: ['Neural Networks', 'Probabilistic Methods', 'Genetic Algorithms', 'Theory', 'Case Based', 'Reinforcement Learning', 'Rule Learning']. \n",
            "Provide reasons for your assessment. Your answer should be less than 200 words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary library (if not already done)\n",
        "# pip install google-genai\n",
        "\n",
        "import os\n",
        "from google import genai\n",
        "from google.genai.errors import APIError\n",
        "\n",
        "# --- IMPORTANT: Set your API Key ---\n",
        "# It's best practice to load your API key from an environment variable.\n",
        "os.environ['GEMINI_API_KEY'] = 'AIzaSyAjX7evzLq__dhbzcJo8uNVkpEyp6JeQQY'\n",
        "client = genai.Client()\n",
        "# Assuming the client is initialized globally or passed in\n",
        "def query_llm_and_generate_description_gemini(prompt, class_list):\n",
        "    \"\"\"\n",
        "    Calls the Gemini API with the TANS prompt and returns the generated text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Initialize client inside if not done globally\n",
        "        client = genai.Client()\n",
        "\n",
        "        # Call the Gemini API\n",
        "        response = client.models.generate_content(\n",
        "            model='gemini-2.5-flash', # Use a capable model like flash or pro\n",
        "            contents=prompt\n",
        "        )\n",
        "\n",
        "        # The TANS explanation is the generated text\n",
        "        llm_explanation = response.text\n",
        "        predicted_class = None\n",
        "        for cls in class_list:\n",
        "            if cls.lower() in llm_explanation.lower():\n",
        "                predicted_class = cls\n",
        "                break\n",
        "\n",
        "        return predicted_class, llm_explanation\n",
        "\n",
        "    except APIError as e:\n",
        "        print(f\"Gemini API Error: {e}\")\n",
        "        return \"Error: Could not generate description due to API error.\"\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return \"Error: An unexpected error occurred.\"\n",
        "\n",
        "# Example Usage (replace the placeholder call):\n",
        "classes_cora = [\n",
        "    \"Neural Networks\", \"Probabilistic Methods\", \"Genetic Algorithms\",\n",
        "    \"Theory\", \"Case Based\", \"Reinforcement Learning\", \"Rule Learning\"\n",
        "]\n",
        "predicted_class, llm_generated_text = query_llm_and_generate_description_gemini(final_prompt, classes_cora)\n",
        "print(f\"Predicted Class: {predicted_class}\")\n",
        "print(f\"Gemini-Generated TANS Description:\\n{llm_generated_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXwJIj2qu22e",
        "outputId": "99b0cc61-e4f2-43db-ce80-dec02cd3b8d1"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: Neural Networks\n",
            "Gemini-Generated TANS Description:\n",
            "The node and its connected papers exhibit a strong overlap in their textual descriptions, with several anonymous keywords appearing frequently across multiple nodes. Most notably, `w1264` is present in all five papers, and `w582` appears in four. Keywords `w875`, `w1072`, and `w1275` are also shared extensively.\n",
            "\n",
            "This high co-occurrence of specific, technical terms suggests a focused research domain with a distinct vocabulary. The node's moderate Degree Centrality (67.06%) indicates it's well-connected within its community, while its low Betweenness Centrality suggests it's not bridging disparate areas. This profile aligns with a paper deeply embedded in a specialized field.\n",
            "\n",
            "Among the given options, **Neural Networks** are characterized by highly specific architectures, algorithms, and components, which often leads to a concentrated and consistently shared technical vocabulary among related papers. This pattern of focused, shared keywords strongly supports a classification in Neural Networks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the Pubmed dataset\n",
        "print(\"--- Loading Pubmed Dataset ---\")\n",
        "dataset = Planetoid(root='./data/Pubmed', name='Pubmed')\n",
        "data = dataset[0]\n",
        "print(f\"Nodes: {data.num_nodes}, Original Features: {data.num_node_features}, Classes: {dataset.num_classes}\")\n",
        "\n",
        "# Convert to NetworkX\n",
        "G = to_networkx(data, to_undirected=True)\n",
        "\n",
        "# Calculate Centralities (Required TANS Step 1)\n",
        "# Note: This is a slow step (especially Betweenness) and is conceptually similar to Cora.\n",
        "degree_centrality = nx.degree_centrality(G)\n",
        "closeness_centrality = nx.closeness_centrality(G)\n",
        "betweenness_centrality = nx.betweenness_centrality(G)\n",
        "\n",
        "# Create DataFrame\n",
        "node_properties_df = pd.DataFrame({\n",
        "    'node_id': list(G.nodes()),\n",
        "    'degree_centrality': [degree_centrality[n] for n in G.nodes()],\n",
        "    'closeness_centrality': [closeness_centrality[n] for n in G.nodes()],\n",
        "    'betweenness_centrality': [betweenness_centrality[n] for n in G.nodes()]\n",
        "}).set_index('node_id')\n",
        "\n",
        "# Calculate Ranks (Required TANS Step 2 for Prompting)\n",
        "for col in node_properties_df.columns:\n",
        "    node_properties_df[f'{col}_rank'] = node_properties_df[col].rank(pct=True) * 100\n",
        "\n",
        "# --- Global Variables for Pubmed Prompting ---\n",
        "# Pubmed has 3 classes (e.g., specific types of diabetic papers)\n",
        "classes_pubmed = [\"Experimental Diabetes\", \"Diabetes Mellitus\", \"Type 1 Diabetes\"] # Placeholder for actual class names\n",
        "sample_node_id = list(G.nodes())[500]\n",
        "sample_text = \"A paper discussing a novel finding related to insulin resistance in mice.\"\n",
        "\n",
        "print(\"Pubmed setup complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gJcqKsE50zq",
        "outputId": "8866be12-3db7-49ae-93fd-ffdda4de1cf9"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading Pubmed Dataset ---\n",
            "Nodes: 19717, Original Features: 500, Classes: 3\n",
            "Pubmed setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- USA Airport Network (Text-Free) Setup ---\n",
        "\n",
        "# This dataset is not part of Planetoid. You would need to load it from a source\n",
        "# like the official TANS repository or the original data source (e.g., using NetworkX\n",
        "# after downloading the edge list).\n",
        "# --- Conceptual Loading ---\n",
        "# G_usa = nx.read_edgelist('usa.edgelist', nodetype=int)\n",
        "\n",
        "# --- MOCKING DATA FOR CONTINUITY ---\n",
        "# Since direct loading is complex, we mock a small text-free graph for demonstration.\n",
        "G_usa_mock = nx.random_geometric_graph(n=1190, radius=0.1) # Mock USA graph (1,190 nodes)\n",
        "\n",
        "# Calculate Centralities\n",
        "degree_centrality_usa = nx.degree_centrality(G_usa_mock)\n",
        "# ... (rest of centrality calculations)\n",
        "\n",
        "# --- Global Variables for USA Prompting ---\n",
        "# Airport classes relate to activity level\n",
        "classes_usa = [\"High Activity\", \"Moderate Activity\", \"Moderately Low Activity\", \"Low Activity\"] # 4 classes\n",
        "sample_node_id_usa = list(G_usa_mock.nodes())[50]\n",
        "sample_text_usa = \"\" # CRITICAL: Text-free means the original text is empty.\n",
        "\n",
        "# When generating the prompt for text-free graphs,\n",
        "# you use the 'generate_tans_prompt' function but pass an empty string\n",
        "# for 'original_text' and the 'get_neighbor_texts' function should be adapted\n",
        "# to return \"No textual descriptions available\" for its output."
      ],
      "metadata": {
        "id": "IwJ_ItpAT5ew"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Re-using the prompt logic with Text-Free adaptation ---\n",
        "\n",
        "def get_original_text_text_free(node_id):\n",
        "    \"\"\"Returns empty string for text-free graphs.\"\"\"\n",
        "    return \"\"\n",
        "\n",
        "def get_neighbor_texts_text_free(graph, node_id, num_neighbors=5):\n",
        "    \"\"\"Returns a placeholder indicating no neighbor text exists.\"\"\"\n",
        "    return \"No textual descriptions available for connected nodes.\"\n",
        "\n",
        "\n",
        "# --- Example Prompt for a Text-Free Graph (USA) ---\n",
        "\n",
        "# 1. Extract node properties as a *DataFrame*, not a Series\n",
        "high_activity_props = node_properties_df.loc[[sample_node_id_usa]].copy()\n",
        "\n",
        "# 2. Add new values safely\n",
        "high_activity_props.loc[sample_node_id_usa, \"degree_centrality\"] = 0.1749\n",
        "high_activity_props.loc[sample_node_id_usa, \"degree_centrality_rank\"] = 99.58  # mock rank\n",
        "\n",
        "# 3. Now generate the prompt using the retained 2D structure\n",
        "final_prompt_usa = generate_tans_prompt(\n",
        "    G_usa_mock,\n",
        "    sample_node_id_usa,\n",
        "    high_activity_props,\n",
        "    classes_usa\n",
        ")\n",
        "\n",
        "print(\"\\n--- Final Generated TANS Prompt Example (USA - Text-Free) ---\")\n",
        "print(final_prompt_usa)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-3gZFoGT79H",
        "outputId": "1c51b124-2816-48e9-d4a3-cd700dbab672"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Generated TANS Prompt Example (USA - Text-Free) ---\n",
            "Given a node from a citation network graph, where the node type is paper.\n",
            "The original node description is: \"No text found for this node.\".\n",
            "\n",
            "The following are the textual information of 5 connected nodes. The descriptions are:\n",
            "372: No text found for this node....\n",
            "77: No text found for this node....\n",
            "226: No text found for this node....\n",
            "946: No text found for this node....\n",
            "471: No text found for this node....\n",
            "\n",
            "Node Properties:\n",
            "- Degree Centrality value: 0.1749, ranked as 99.58% among all nodes.\n",
            "- Closeness Centrality value: 0.1458.\n",
            "- Betweenness Centrality value: 0.0000.\n",
            "\n",
            "Output the potential class of the node among the following classes: ['High Activity', 'Moderate Activity', 'Moderately Low Activity', 'Low Activity']. \n",
            "Provide reasons for your assessment. Your answer should be less than 200 words.\n"
          ]
        }
      ]
    }
  ]
}